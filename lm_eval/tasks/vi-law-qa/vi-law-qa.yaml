# tag:
#   - legal
#   - vietnamese
# task: vi-law-qa

# # Dùng file JSONL local
# dataset_path: json
# dataset_name: null
# dataset_kwargs:
#   data_files:
#     test: ./lm_eval/data/vi-law-qa.jsonl

# # Chạy trên split "test"
# training_split: null
# fewshot_split: test
# test_split: test

# # Kiểu đánh giá
# output_type: multiple_choice

# # Prompt hiển thị cho mỗi câu hỏi
# doc_to_text: |-
#   {{question}}
#   A. {{choices[0]}}
#   B. {{choices[1]}}
#   C. {{choices[2]}}
#   D. {{choices[3]}}
#   Trả lời bằng A/B/C/D:

# # Cho mô hình biết các lựa chọn và đáp án đúng
# doc_to_choice: ["A", "B", "C", "D"]
# doc_to_target: "{{ ['A','B','C','D'][answer_idx] }}"

# metric_list:
#   - metric: acc
#     aggregation: mean
#     higher_is_better: true

# # Tuỳ chọn: ép mô hình trả lời ngắn gọn
# generation_kwargs:
#   do_sample: false
#   temperature: 0.0

tag:
  - legal
  - vietnamese
task: vi-law-qa

# Dùng file JSONL local (tách test và few-shot)
dataset_path: json
dataset_name: null
dataset_kwargs:
  data_files:
    train: ./lm_eval/data_fewshot/vi-law-qa.jsonl   # <= file few-shot riêng
    test:  ./lm_eval/data/vi-law-qa.jsonl

# Chạy trên split "test"; lấy few-shot từ "train"
training_split: null
fewshot_split: train
test_split: test
num_fewshot: 8   # số ví dụ few-shot (có thể override bằng --num_fewshot)

# Kiểu đánh giá
output_type: multiple_choice

# Prompt cho mỗi câu hỏi
doc_to_text: |-
  {{question}}
  A. {{choices[0]}}
  B. {{choices[1]}}
  C. {{choices[2]}}
  D. {{choices[3]}}
  Trả lời bằng CHỈ MỘT KÝ TỰ là chỉ số của đáp án đúng:
  0 cho A, 1 cho B, 2 cho C, 3 cho D.
  Trả lời (0/1/2/3):

# Các lựa chọn và đáp án đúng theo INDEX
doc_to_choice: ["0", "1", "2", "3"]
doc_to_target: "{{ answer_idx }}"

metric_list:
  - metric: acc
    aggregation: mean
    higher_is_better: true

# Ép mô hình trả lời một token, không lấy mẫu
generation_kwargs:
  do_sample: false
  temperature: 0.0
  max_new_tokens: 1
